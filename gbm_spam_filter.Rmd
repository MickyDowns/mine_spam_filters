---
title: "gradient boosting: spam filter"
output: html_document
---

###6 spam email
```{r}
library(gbm)
library(caret)

spam=read.csv("Spam_Train.txt",header=FALSE,sep=",",
                  quote="\"",dec=".",fill=TRUE,comment.char="")

#spam<-read.table("http://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data",sep=',')

spam.test=read.csv("Spam.Test.txt",header=FALSE,sep=",",
                  quote="\"",dec=".",fill=TRUE,comment.char="")

rflabs<-c("make", "address", "all", "3d", "our", "over", "remove",
  "internet","order", "mail", "receive", "will",
  "people", "report", "addresses","free", "business",
  "email", "you", "credit", "your", "font","000","money",
  "hp", "hpl", "george", "650", "lab", "labs",
  "telnet", "857", "data", "415", "85", "technology", "1999",
  "parts","pm", "direct", "cs", "meeting", "original", "project",
  "re","edu", "table", "conference", ";", "(", "[", "!", "$", "#",
  "CAPAVE", "CAPMAX", "CAPTOT","type")

colnames(spam)<-rflabs
colnames(spam.test)<-rflabs

table(spam$type)
table(spam.test$type)

## training
set.seed(131)
x<-spam[sample(nrow(spam)),] # randomize the rows of data before fit the model in case that the responses in the original data are monotonic increasing or all 1 responses are at the top while the remaining 0 are at the bottom.
x.test=spam[sample(nrow(spam.test)),]

# part A
set.seed(444)# Random for bag.fraction
gbm0<-gbm(type~.,data=x,train.fraction=0.8,
          interaction.depth=4,shrinkage=.05,
          n.trees=2500,bag.fraction=0.5,cv.folds=5,
          distribution="bernoulli",verbose=T)

 # interaction depth: 1 implies an addictive model, the so called stump tree; 2 implies a model with up to 2-way interaction.

# shrinkage: A shrinking parameter to scale the contribution of each tree in the model.

# cv.folds: If cv.folds=5, the model will per- form a 5 fold cross-validation and output. If it is computational feasible, it is always recommended to add this parameter for the use of best number of iteration selection later.

# may want to try adaboost vs. bernoulli

## results of fit
gbm0$fit # Vector containing fitted values on scale of the loss function. Here it is log-odds since our distribution is “bernoulli”. Under the “bernoulli ”distribution, we can use the predict function to return the probability of responses by specifying the type as response.

## prediction
gbm0.predict<-predict(gbm0,x,type="response",n.trees=300)
hist(gbm0.predict)
preds=rep(0,length(gbm0.predict))
preds[gbm0.predict>0.5]=1
confusionMatrix(data = preds, x$type)

gbm0.predict.test<-predict(gbm0,x.test,type="response",n.trees=300)
hist(gbm0.predict.test)
preds=rep(0,length(gbm0.predict.test))
preds[gbm0.predict.test>0.5]=1
confusionMatrix(data = preds, x.test$type)

# relative importance
summary(gbm0,main="relative influence: all predictors")

# partial dependence
par(mfrow=c(1,3))
# optimal iterations. apparently cross-validation is best. 
gbm.perf(gbm0,method="test") #plot the curve for error rate and number of iterations. return the value of the optimal number of iteration according to the criterion specified by the parameter “method ”
gbm.perf(gbm0,method="cv")
gbm.perf(gbm0,method="OOB")

# finding optimal number of iterations based on type of validation
best.iter_test<-gbm.perf(gbm0,method="test")
best.iter_test
best.iter_OOB<- gbm.perf(gbm0,method="OOB")
best.iter_OOB
best.iter_cv<-gbm.perf(gbm0,method="cv")
best.iter_cv

par(mfrow=c(2,5))
for(i in c(53,52,7,25,16,55,21,56,57,5)){
     plot(x=gbm0,i.var=i,n.trees=best.iter_cv)
}

par(mfrow=c(1,1))
plot(gbm0,c(25,52),best.iter_cv,main="'!' and 'hp'",xlim=c(0,3),ylim=c(0,1))

# part b
# importance of predictors
imp.pred.rel=summary(gbm0,main="Predictors: Relative Influence")
top.pred.rel=imp.pred.rel[imp.pred.rel$rel.inf>0,]
imp.pred.per=summary(gbm0,method=permutation.test.gbm, main="Predictors: Permuation Test")
top.pred.per=imp.pred.per[imp.pred.per$rel.inf>0,]
top.pred=intersect(imp.pred.rel$var,imp.pred.per$var)

# build better spam filter
## validate final on validation (test)
## if necessary, dial-up probability

scr.fit <-function(weight,prob,actuals,preds) {
     # sum predictions by outcome
     tp=sum((preds==1 & preds==actuals))
     tn=sum((preds==0 & preds==actuals))
     fp=sum((preds==1 & preds!=actuals))
     fn=sum((preds==0 & preds!=actuals))
     # calculate rates
     fpr=fp/(fp+tn)
     fnr=fn/(fn+tp)
     miscl=(fp+fn)/(tp+tn+fp+fn)
     # format results
     result=as.data.frame(matrix(NA,1,6))
     names(result)=c("weight","prob","fpr","fnr","miscl","scr")
     result[1,1]=weight
     result[1,2]=prob
     result[1,3]=fpr
     result[1,4]=fnr
     result[1,5]=miscl
     result[1,6]=((1-fpr)*weight+(1-fnr))/(weight+1)
          #sigmoid((10*posprod^(1/3)+precision^2))
     return(result)
}

# forward search for best predictors
## initialize
rm(scr.mstr)
all.preds=1:57

weight.thresh=c(5)
for(g in weight.thresh){
     
     prob.thresh=c(0.95)
     for(h in prob.thresh){
          
          improving=TRUE
          best.preds=1
          top.preds=rep(0,10)
          model.preds=NULL
          model.max=0
          best.scr=0
          i=1
          
          while(improving==TRUE){
               # create train and test sets
               inBuild=createDataPartition(y=x$type,p=0.7,list=FALSE)
               train=x[inBuild,];test=x[-inBuild,]
               test.preds=all.preds[-best.preds]
               
               cat("******** i: ",i,", j: ",j)
               
               test.preds=all.preds[-best.preds]
               for(j in test.preds){
                    model.preds=best.preds
                    model.preds[i]=j
                    
                    # fit / predict
                    fit<-gbm(type~.,data=train[,c(model.preds[1:i],58)],
                             train.fraction=1,
                             interaction.depth=4,shrinkage=.05,
                             n.trees=2500,bag.fraction=0.5,cv.folds=0,
                             distribution="bernoulli",verbose=F)
                    probs<-predict(fit,test[,c(model.preds,58)],
                                   type="response",n.trees=300)
                    preds=rep(0,length(probs))
                    preds[probs>h]=1
                    
                    # scr results
                    scr=scr.fit(g,h,test$type,preds)
                    if(scr$scr>model.max){
                         top.fit=fit
                         top.preds[1:i]=model.preds
                         scr=cbind(scr,t(as.data.frame(top.preds)))
                         
                         if(exists("scr.mstr")){
                              scr.mstr=rbind(scr.mstr,scr)
                         }else{
                              scr.mstr=scr
                         }
                         model.max=scr$scr
                    }
               }
               best.preds=top.preds
               if(model.max>best.scr){
                    best.scr=model.max
               }
               else{
                    improving=FALSE
               }
               i=i+1
               print(scr.mstr)
          }
     }
}

# top predictors
par(mfrow=c(1,1))
summary(top.fit,main="relative influence: all predictors")

# partial dependence
par(mfrow=c(1,3))
# optimal iterations. apparently cross-validation is best. 
gbm.perf(top.fit,method="test") #plot the curve for error rate and number of iterations. return the value of the optimal number of iteration according to the criterion specified by the parameter “method ”
gbm.perf(top.fit,method="cv")
gbm.perf(top.fit,method="OOB")

# finding optimal number of iterations based on type of validation
best.iter_test<-gbm.perf(top.fit,method="test")
best.iter_test
best.iter_OOB<- gbm.perf(top.fit,method="OOB")
best.iter_OOB
best.iter_cv<-gbm.perf(top.fit,method="cv")
best.iter_cv

names(spam)
par(mfrow=c(2,5))
for(i in c(3,2,8,1,7,9,6,4,10,5)){
     plot(x=top.fit,i.var=i,n.trees=best.iter_OOB)
}

#plot(top.fit,c(2,3),best.iter_OOB,ylim=c(0,3),main="Partial Dependence on '!' and 'CAPMAX'")
#plot(top.fit,c(2,3,8),best.iter_OOB,ylim=c(0,3),main="Partial Dependence on '!', 'CAPMAX','$'")

```
